---
layout: subpage
title: Ethics of Care
image: css/gilligan.png
subpage: true
coursepage: false
---

## “Caring requires paying attention, seeing, listening, responding with respect. Its logic is contextual, psychological. Care is a relational ethic, grounded in a premise of interdependence. But it is not selfless.”
### ― Carol Gilligan, *Joining the Resistance*

# Website Post 7

## Summary of Computer Assisted Warfare

Until very recently, war has been an act taken between humans. We engaged each other as humans, and when the decision to kill had to be made, that finality was reached at the hand of a thinking, feeling, person. With the advent of computerized weapons systems, that has changed, introducing a whole host of ethical questions. On one hand, these systems could reduce the need for human casualty, since a robot need not defend itself. On the other hand, robots could malfunction, unleashing a torrent of unconstrained lethal force. To address the first point from within the framework of the Ethics of Care, it’s important to realize that these systems are, and would be, programmed by humans. They would make decisions only as ethical as their programmers instruct them to. And so if, for example, a UAV, were programmed to emulate a human pilot, then we wouldn’t see the robot being more humane. At best, it would be only as humane, not accounting for errors. During the United States drone engagements in the Middle East, wherein thousands of innocent civilians, including children, were hurt or killed, would a robot programme to do exactly as the humans would have been any more humane? Probably not. The Ethics of Care emphasises this human element, and so recognizes the possibility that these robots are used to enforce an oppressive hegemony without the risk of militaristic engagements coming back to harm the instigators. The Ethics of Care also recognizes the possibility of malfunction, and the hazards that presents to humans. These things considered, the Ethics of Care stands against the computerization of warfare.

## Summary of Online Censureship

Online censorship is the suppression of information on the Internet. This has caused many issues such as internet users not being able to access the information they desired and people not being able to provide the material they desired. All users of the internet should be able to access public information as they wished. The framework of the ethics of care focuses on taking responsibility for those who are vulnerable and they are the internet users who could not obtain or publish the information on the internet. The ethics of care support those who are unable to obtain the public information they desired and provide ways for them to voice their own opinions on online platforms. Specifically, in the EU, operators of digital platforms will have to crowdsource a database of materials with copyrights that users essentially censored if posted these materials. Many believe that it’s dangerous to ask tech companies to decide what’s legitimate free speech. As digital platforms and social media are becoming a very common way of human interaction, all users become vulnerable to the regulation from governments and tech companies. In many other countries, certain websites are not allowed access due to information regulation laws. Internet users from these countries become helpless regarding the information they wish to access. Actions like this from governments are against the ethics of care and those who are susceptible to censorship should have their rights of information access protected.

## Summary of Job Automation

Job automation is a pressing issue that has a lot of people torn somewhere in between scared and excited. On one hand, technology is advancing at an unprecedented rate, so many would like to capitalize on the fruits of our labor and make as many things as convenient as possible. On the other hand, since society hasn’t experienced advancement like this since the industrial revolution, many fear the predicted and unforeseen consequences of making such a drastic change. Specifically, the mass loss of jobs across fast food chains and several major industries. It is for this reason that ethics of care would suggest taking a position against job automation, or more importantly at least against job automation on a large scale. An immediate switch to automation would leave countless people without a source of income or a similar lower-skill job to turn to, which would be completely unattentive, irresponsible, and overall damaging to the relationships involved through these companies. If the companies involved (or some other entity, government, etc) was involved enough to provide sufficient warning, resources, funding, or some sufficient means of help to employees being laid off, Care Ethics would suggest that job automation would actually be the moral thing to do, all parties (higher level executives, employees, consumers) considered.

## Algorithm For Ethical Framework Decisions

The inputs to the algorithm are:

P 	= a list of people that are impacted by the decision

E 	= a list aligned with P of the effects the decision being taken has (can be +/-)

E’	= a list aligned with P of the effects the decision not being taken has (can be +/-)

S  	= effect of the decision being taken has on individual making the decision

S’  	= effect of the decision not being taken has on individual making the decision

Assume that we have a function that returns a vulnerability_weight for any person (higher weight means more vulnerable). Assume total of effects and non-effects add up to 0

```
ethics_of_care(P, E, E’, S, S’):
# find all of the negative vulnerability score with the action being taken
negative_people_for = list()
for i, p in P: if E[i] < 0: negative_people_for.append(i)

	if len(negative_people_for) == 0 && S > 0: return “Ethical”

# Otherwise, find out if there are any vulnerable parties that are worse than the decider
worst_off_for=vulnerability_weight(D)*S, num_worse_for = 0
for i in  negative_people_for:
	if vulnerability_weight(P[i])*E[i] > vulnerability_weight(D)*S
		if worst_off_for > vulnerability_weight(P[i])*E[i]
worst_off_for = vulnerability_weight(P[i])*E[i]
		num_worse_for++

# Now, do a similar thing for people against the decision
negative_people_against = list()
for i, p in P: if E’[i] < 0: negative_people_against.append(i)

# Otherwise, find out if there are any vulnerable parties that are worse than the decider
worst_off_against=vulnerability_weight(D)*S’, num_worse_against = 0
for i in  negative_people_for:
	if vulnerability_weight(P[i])*E’[i] > vulnerability_weight(D)*S’
		if worse_off_against > vulnerability_weight(P[i])*E’[i]
worst_off_against = vulnerability_weight(P[i])*E’[i]
		num_worse_against++

	# Compare results
	if num_worse_for > num_worse_against && worse_off_for < worse_off_against:
		return “Unethical”
	elif num_worse_for > num_worse_against:
		return “Probably Unethical
	elif worse_off_for > worse_off_against:
		return “Ethical”
	else:
		return “Probably Ethical”
```

# Website Post 6

## Summary of Key Issues and Potential Stake Holders in Job Automation

There are several groups greatly impacted by job automation. The first group is that of the workers that job automation looks to replace. The second group is the owners and shareholders of the company that is looking to transition job automation. The third group is the consumers and the general population that will not only reap the benefits of job automation but also have to confront the problems that it creates.

The workers that will be replaced by job automation will feel the impact immediately. Losing their job, they will be forced to attempt to find another. Unemployment will not only affect them but also will affect their families and communities. The problem is that if the job they had has become automated, and they only have the skills and education for that job, it will be more challenging to find a similar position. One course of action is to go back to school and get retrained in a job with a higher skill requirement. While some look at this as a very good thing, it tends to be a lot harder than it sounds. For many of these workers, they were living paycheck to paycheck, and cannot afford to go without pay for an extended period of time.

The owners and shareholders are the driving force behind automation. The main benefit to them is that they will make more money. This makes these executives seem evil, which is not the case. Business is about competition and if a company does not innovate, they will fall behind and, eventually, everyone will lose their jobs. So, the executives and shareholders of a company have a responsibility to keep the company on the cutting edge. However, if widespread automation leads to unemployment rates skyrocketing, an economic recession will most likely occur. In which case, the executives and shareholders will lose a lot of money.

Lastly, the customers and the general population will feel the effects of automation. On one hand, products will be produced more efficiently, and, in theory, prices will go down and quality will go up. However, again, if unemployment rates go up and a recession happens, everyone will be negatively affected by this.

According to the framework of ethics of care, the engineers in designing job automation system should be morally responsible for the human workers who lose their jobs. Ethics of care is centered around supporting those who are weak and unprotected and these workers whose jobs are replaceable by technologies designed by engineers are certainly vulnerable. And engineers who designed the system which directly caused the loss of jobs have solved a financial problem for the company but cause bigger issues within these workers family. The ethics of care encourages helping the vulnerable and provide them with help. These engineers work causes social issues and are against the ethical framework of the ethics of care. 

## Analysis of Job Automation

Those in opposition of job automation largely agree that the most worrying part is the short-term effect of a mass transition to job automation. A study found that 35% of current jobs are at risk of being replaced over the next 20 years. If the number of companies simultaneously working towards automation was limited, this situation would be less urgent; however, unfortunately, that is not the case. As we’ve already seen in China, after a company that supplies Apple and Samsung cut more than half of its 110,000 employees, others are quick to follow. With a quick shift to automation, millions around the world may be left without a source of income at an alarmingly quick rate. 

Furthermore, many are concerned with the possible unforeseen consequences of job automation. Taking away jobs at such a large scale would be removing a part of our cultural identity as a nation. Former Treasury Secretary Lawrence Summers, who has seen first-hand the inner workings of the country’s economy, has his doubts about suddenly removing the way of life of many Americans. Others simply fear the effects of letting technology overrun every aspect of our lives. Ultimately, most people opposing job automation are afraid of the uncertainty of a quick global shift towards automation and the unpredictable outcomes it may have.

One of the biggest proponents to job automation is that it will save a company a lot of money in the long run. A company can make a one time purchase of a machine that can automate the  job of 5 people. Unlike a machine, these 5 people must be paid a salary for every year they work. As such, job automation is usually a huge monetary investment made by the company. On a similar note, automation allows for higher production rates as a machine can typically work faster and more efficiently than a human can, both of which can increase the profits made by the company. Since machines are more precise, they can increase the safety of workers in the workplace. Machines do not get tired or momentarily lose focus like humans, which at times can cause accidents in the workplace. Allowing for automation could make the workplace more safe in jobs that require attention due to safety reasons. Finally, since machines can more efficiently do human’s jobs it could free up the amount of time humans need to spend working. By doing this, humans can spend less time at work and more time with their family. 

When looking at the arguments for and against job automation in the eyes of the Ethics of Care, one must as always consider the relationships involved with such a change. In a traditional, healthy workplace, there exists a number of workers, which can vary based upon the size of the company in question. Regardless, the workplace is a space for the development of both professional and personal relationships, and for most working adults, it can be the major source of relationships outside of the family. The automation of jobs would certainly cause a decreased number of people in the workplace, and in some cases, the need for human workers might even be eliminated. Because of this, one could argue that the increase of job automation will lead to a decrease in relationships in the workplace. Rather than being an environment where mature adult relationships can flourish, the replacement of humans with machines will introduce a lack of personality and interchange of ideas. For this reason, the Ethics of Care would take a stance against job automation on the grounds that relationships would be damaged and largely removed by it. In the end, even though automation may increase efficiency and reduce human error, this does not provide sufficient reason to sacrifice the value human interaction in the workplace.
 
Another argument that would be put forward by the Ethics of Care framework is that one must scrutinized which parties would benefit from job automation, and which ones would be at a loss. Corporations as an entity would definitely gain from increased efficiency and less overhead for workers, yet on the other hand, all levels of workers would be affected negatively. The security of jobs from all sectors of the workplace would be in peril, and therefore workers would be placed in a very vulnerable position. As the Ethics of Care places a great emphasis on caring for the vulnerable, it would be firmly against job automation on these grounds as well, since workers would need to be protected against the prospect of losing their jobs to machines. Furthermore, Ethics of Care would say that job automation should be avoided in the first place to save workers from being placed in this vulnerable position.
 
In the case where job automation is utilized to automate tasks that were originally considered dangerous or harmful to humans, Ethics of Care would lean towards supporting this action. Some examples could include jobs that deal with hazardous waste and other materials, or possibly construction/maintenance jobs dealing in risky situations. Job automation would not only save companies the problem with risking human lives, but workers could also benefit by not placing themselves in danger. In this small subset of jobs, job automation would indeed by sensible and in line with the tenets of the Ethics of Care. Once again, this highlights the importance of considering all aspects of an issue when trying to apply an ethical framework.


## Analysis of Self-Drivng Cars

Proponents of self-driving cars argue that there are a variety of benefits to them from increasing public safety to reducing traffic times. One of these benefits is the inevitable decrease in lives lost if self-driving cars are fully implemented. As of 2017, car accidents are in the top 10 greatest causes of death in the united states, and using computer systems to drive cars would reduce the human error that is involved in car accidents, including acts such as texting and driving and drinking and driving. While most studies performed on number of lives lost agree on a figure of about 80% reduction, which is about 30,000 lives per year, even the most cynical study that could be found on the internet still claimed that 10,000 lives per year would be saved. Proponents hence claim that this should be a major point in the public eye, especially compared to major public debate topics such as mass shootings, which have only caused 1,000 deaths in the past 50 years combined.
Also, it is widely agreed that self-driving cars would greatly reduce traffic due to the increased communication allowing for the cars to be more easily maneuvered and the elimination of rubbernecking, one of the largest causes of traffic in the United States. Therefore, due to the number of lives saved and the amount of time saved, it makes logical sense to implement self-driving cars nationwide.

Opposition to self-driving cars revolves around morality ethics. Coders, the government, and everyday people express fears of having to decide what system of morality should be implemented into the programming of self-driving cars. The most commonly alluded to an ethical scenario in which self-driving cars may encounter is the archetypal trolley problem. The trolley problem presents a case in which a runaway trolley is speeding down a track and reaches a fork in the track. The trolley will, without intervention, continue forward and kill a group of people, or an onlooker can push a lever and direct the trolley down another track to kill a single person. This scenario begs the question of when and what lives to say in time of inevitable disaster. This is the principal quarry that opponents of self-driving cars have. Penned as the “social dilemma of autonomous vehicles,” programmers and scientists alike debate what lives should be prioritized by these vehicles in case of disaster: the inhabitants of the vehicle or the general public? To form any sort of answer to this question is rejected by opponents of autonomous vehicles as programmers would have to inject personal moral systems into these machines. In case of disaster, autonomous vehicles would have to discriminate and target individuals to bear the brunt of either a technological mishap or incalculable accident. To attempt to program any sort of moral system into these machines is to introduce unintended consequences into the sector if self-driving vehicles.

Self-driving cars are a hot topic today and many people have differing opinions on if they should or should not be allowed to be used in everyday life. Their use presents a number of questions regarding privacy, for example. Could malicious actors steal information about victims’ location? And is it ethical to potentially open people up to that vulnerability? Our ethical framework requires at least that mitigating factors being taken. On the other hand, self driving cars have the potential to connect people, and allow people who don't drive more mobility. And despite the ethical questions, self driving cars do have a huge potential to make driving safer for everybody. All things considered, the potential of self driving cars to help people, to grant mobility to those would would otherwise be limited, to keep people safe, etc. makes self driving cars a net positive for our ethical framework.

Especially taking into account the saftey factor self-driving cars have the advantage of being able to make one of the most dangerous activites a human can do today and make it immeasurably more safe. This can help bring people together especially the ealderly and the young who otherwise couldn't drive. Our framwork would also be a proponent of an all encompassing system that doesn't allow for manual operation as this has the highest chance of being the safest way to operate cars autonmously; all cars driving themselves in a connected way. This encourages stronger relationships between people which is again a positive for our framework.



# Website Post 5

## Summary of Net Neutrality

### Key Stakeholders

* ISP Companies and their Subsidiaries 

* Large Internet Companies (Netflix, Facebook, Google, etc…)

* Users (People who pay for internet access from ISP including homes and businesses)

* The Government (Regulator of the Rules)

### Summary of Core Beliefs and Positions
**ISP Companies:**	The ISP Companies are the companies that people and business pay in order to gain access to the internet. With Net Neutrality these companies must by law provide equal access to all of the content on the internet. This means that if someone pays for the internet the ISP must provide ALL of the content on the internet at the advertised speed. On the other hand, if Net Neutrality does not exist these ISP’s could throttle certain content, even charge more for access to certain services like Facebook or Netflix. Something else that could also happen if Net Neutrality laws are not in place is you could type in www.google.com and your ISP serves you www.yahoo.com because they have a marketing agreement with yahoo!. 

**Large Internet Comapnies:** The large internet companies like Google, Facebook, and Netflix all have vested interests in Net Neutrality because their entire product is online. If ISPs decide to regulate who can access what services for what price this could have a major impact on who their product reaches and in turn their revenue from ads that they host on their services or the subscriptions fees they charge. If people had to pay an access fee for Netflix on top of the Netflix subscription price it could potentially severely cut into Netflix’s revenue. On the other hand, these companies could potentially partner with the ISPs to push their own content, for instance, Google could pay an ISP to serve their Google+ platform every time someone tries to access Facebook. 

**Users:** The users are probably the most helpless group in this situation. With Net Neutrality everyone who pays for some form of internet service has equitable access. Without Net Neutrality laws only the rich might be able to access all of the internet and those that cannot afford that will only be able to access certain parts of it or will have to sit through many ads in order to access a single web page. 

**Government:** The government is the organization what will decide if any of Net Neutrality will stand and they are heavily influenced by lobbyists on both sides of the debate. It would be interesting to see if they did repeal Net Neutrality if they would include a clause in the law that states that ISPs must provide equal access to government websites. In other words, would the government ensure that access to their own web services is equal for all?

## Analysis of Deplatforming

### Summary of Opposition to Deplatforming

One of the biggest opposition to deplatforming comes from the idea that deplatforming an individual is a violation of their 1st amendment right to freedom of speech. Many of the individuals who have been deplatformed, such as Alex Jones, believe that deplatforming is specifically targeting conservative groups and individuals as a way to try to silence them and the information that they try to provide to the world. As such, these individuals claim that they have a right to share their thoughts with the world and that being deplatformed is a violation of their freedom of speech. Another opposition to normalizing deplatforming is that it enforces the creation of echo chambers. Echo chambers are spaces on the internet the lack the views that are against or in opposition of your own and where the opinions around you will all reinforce and reaffirm your own views. As such, deplatforming groups and individuals who have different views than the average user on a platform would essentially be creating an echo chamber for those users. People argue that this is dangerous as it can be arbitrary as to what views should warrant being deplatformed based on the beliefs or views of a majority that uses the platform. Finally, a study showed that banning the spaces in which hate speech and racism is discussed is more efficient at eliminating toxic content from a platform than merely banning individuals. As such deplatforming on its own won't contribute much in the solution of ridding the internet of violence causing hate speech, which many people argue is a big reason for deplatforming individuals.

### Summary of Proponents of Deplatforming

The biggest proponent of deplatforming is the idea that deplatforming would prevent the spread of hate speech and violence on the internet. This argument argues that this type of hate speech reaches out to vulnerable and marginalized individuals and radicalizes them by influencing their views and beliefs. As seen in the past, communities with toxic content have shown to influence and inspired individuals to act violently in real life, and example of this would be the pizzagate conspiracy. As such getting individuals who harbor and spread hate speech and misinformation deplatformed would minimize the amount of hate speech and violence by ultimately taking away their main tool. Another proponent to deplatforming is that companies can decide what can be said and not said if you decide to use their platform. As such, allowing deplatforming would be supporting the rights of content creators to exercise their power in deciding what is allowed on their website through community standards and punishing those who do not adhere to those standards. In doing so, the company can take a stance on social problems and distance themselves from views and actions that they do not not condone.


### Stance on Deplatforming

As with all issues viewed in the scope of the Ethics of Care, one must scrutinize the relationships involved and affected by the act of deplatforming. Because of this, one must take into account two different situations in which someone or a particular group would be deplatformed.
The first situation involves the deplatforming of a party that is attempting to propagate an alternative, or even “radical”, view over social media or just the media in general. In this case, if no particular group is being targeted, Ethics of Care would be against deplatforming. Restricting this type of free thinking and speech is something that would certainly detract from healthy, diverse relationships. This is because without the existence of multiple perspectives and opinions, relationships cannot evolve and flourish. Therefore, as long as no people or groups are being targeted or threatened directly, even radical thinking should be permitted to allow for a diversity of views. Furthermore, Ethics of Care aims to defend the vulnerable and underrepresented, so certain radical views would most likely be in the minority and must be protected according to Ethics of Care.

Another aspect of deplatforming involves removing an entity from social media or similar mediums due to hateful or threatening speech or actions. In this case, one can without a doubt observe that such behavior can only serve to tear down healthy relationships between people, particularly the relationships between different groups of people. In fact, hate speech and threats against other people is the antithesis of attempting to form good relationships. Accordingly, it is clear to see that Ethics of Care would be strongly for the deplatforming of people or groups that use social media to propagate hateful and threatening rhetoric. As stated above, the Ethics of Care places a great emphasis on caring for the vulnerable, and certainly in this case, the receivers of hate and threats would be placed in a vulnerable position. Deplatforming and silencing this behavior would be an effective first step to caring for the victims.

As can be seen by the arguments above, the Ethics of Care would not have a clear cut, generalized response to the act of deplatforming. Rather, one must delve deeper into the situation and take into account the parties involved, in order to fully incorporate this ethical framework. What is most important is the people affected by both the deplatforming and the reasons why deplatforming was deemed necessary in the first place. Ultimately, if social media is used to spread a new and possibly even controversial opinion, then this should be allowed, as a diverse abundance of views can indeed be beneficial to creating mature, well-informed relationships between people. When the use of social media reaches the point of truly hateful speech or outright threats, this is when Ethics of Care would step in to support deplatforming the offending party, for such behavior is destructive to all forms of relationships. In the end, a little extra diligence is required when making a decision on deplatforming under the guidance of the Ethics of Care. This deeper level of introspection and care is interestingly a core tenet of the Ethics of Care, and therefore, the case of deplatforming excellently highlights the ethical thought process of this framework.


## Could Deplatforming Impact Online Echo Chambers

### Summary About Echo Chambers

Online echo chambers are platforms on the internet where you receive content that is similar to what you believe or post. Companies such as Facebook and Twitter focus on trying to create online communities where people want to spend time. To do this, they setup an environment that allows people to see personalized content that they want, often times being content that they agree with. This can be either posts’ from friends or media outlets that align with their beliefs and interests. The algorithms are designed to generate more traffic on the site so they tend to reinforce the user’s view and opinions, which generally makes the user spend more time on the site. The problem is that the algorithms controlling this content prevent users from seeing dissenting views. This can lead to further polarization and less discussion and empathy on controversial issues, which is the main threat echo chambers pose. Another issue in the same vein as echo chambers is deplatformization. Deplatformization refers to an online platform company removing a user’s account who has offended a large group of people or crossed several lines. The question inevitably becomes should a company be able to take away a user’s platform, and, if so, where should the line be drawn? If a company wields this power too frequently, their platform can become a large echo chamber excluding a perspective on a certain issue. If a platform grants unlimited free speech, it may create a hostile online environment that discourages users from participating in the community. 

### Summary of Recent Deplatforming Attempts and Outcomes

Recently, a number of prominent (and more not so prominent) online figures have been deplatformed. For the most part, the deplatformings have had public support, since the reason for nearly all the bans is related to racism, bigotry, and/or inciting violence. InfoWars host Alex Jones had the most notable deplatforming in the last calendar year; however, many believe the act was a long time coming. Jones has a history of hate speech and spreading misinformation, and users across social media platforms had been calling for his removal for some time. The deplatforming of Alex Jones, like most recent deplatformings, was publicly demanded, and therefore was accepted by a large majority of users. Additionally, the observable outcomes of the bans have been positive across the platforms. For example, when Reddit banned subreddits with hate-speech, there was an overall drop in hate-speech on the site. Also, with sites like Paypal deplatforming these people, the lack of funding makes it much harder for them to promote their dangerous messages. 

At the moment, the outcomes of deplatformings have been good. The backlash, if any, is largely from the niche subsets of followers of the people being banned, and online communities have become safer and more positive on the whole. There is, of course, a danger that arises when the tech giants subjectively can choose who to deplatform, although we haven’t seen a situation with a largely negative outcome yet.

### Argument If Deplatforming Affects Online Echo Chambers

Some echo chambers are unavoidable. Deplatformization, when implemented correctly, can be used to create echo chambers that do the least harm. Whenever someone is deplatformed it is usually to silence their opinions or behavior on the site. So, essentially when someone is deplatformed, their perspective is taken away from the site. This creates a space that is void of a certain perspective, which is an echo chamber by definition. However, there are certain echo chambers that are tolerable. Every individual may have their own opinions on what echo chambers are tolerable, but I believe that a large majority of the population can find common ground on a few, and for those few, it is okay to use deplatformization to create them. One of the cases where echo chambers are tolerable is when a certain user is harassing individuals to the point where their views are silenced. Because of that user’s actions, perspectives are not being contributed to the site, creating an echo chamber. Obviously, this is very subjective, in which case, a diverse group of people who work for the site should review the posts by the user and make a decision. To implement this fairly, deplatforming a user should be done on a case by case basis.

It should be noted that some people have raised concern if deplatforming could actually increase the negative effect of online echo chambers. For example, with Alex Jones off of major social media sites, devout followers are more likely to either visit his site directly or view/discuss his content elsewhere, where they may run into other or more dangerous fringe material. While deplatforming, to this point, has had an overall positive outcome on the major platforms, it may lead to worse outcomes for those easily influenced by dangerous ideas on the internet. The impact of situations like that cannot be measured, but, while certainly not the norm, it is something to consider.


# Website Post 4

## IBM Case Brief

### Relevant Facts

* IBM’s German subsidiary’s top management was comprised of openly rabid Nazis who were arrested after the war for their Party affiliation

* IBM knew that it was courting and doing business with the upper echelon of the Nazi Party.

* The company leveraged its Nazi Party connections to continuously enhance its business relationship with Hitler's Reich.

* IBM subsidiaries trained the Nazi officers and their surrogates throughout Europe.

* IBM's machines tabulated and tracked census information in order to identify Jewish populations across Europe.

* Slave labor was identified, tracked, and managed largely through punch cards. Punch cards even made the trains run on time and cataloged their human cargo.

* IBM maintained sales quotas for all its subsidiaries during the Hitler-era.

* Everything was leased and regularly maintained by IBM technicians, some of who serviced the tabulation machines biweekly on-site at the concentration camps 

### Listing of Stakeholders

1. __IBM__ - Condemned actions of Nazis. They claimed that IBM loss control of their German subsidiaries. As such they believe that IBM was not directly responsible. 

2. __Holocaust Survivors__ - IBM’s technology allowed for the mass extermination of Jews that would have otherwise not happened (to that extent) if IBM and their subsidiaries did not aid the Germans with their punch card machines. As such IBM is responsible for their share of contributions to the atrocities. 

3. __Present and Future Consumer Companies__ - They may feel that they are not responsible for how their products are used, and that responsibility ends at purchase. “Rope makers not responsible for those who hung people with them”.

### Statement on Ethical Culpability of IBM

The Ethics of Care believes that those affected by one's choices should be considered with proportion to their vulnerability. It is apparent that initially IBM could not have foreseen what their technologies would be used for the atrocities of the holocaust. The Ethics of Care would say that initially IBM would have not been found culpable for the atrocities, given that they simply be nurturing their interests by pursuing existing and new business relations. Despite this, the Ethics of Care would find IBM partly responsible when, as the facts state, they found out what their technology was being used for. In this instance, the ethics of care would prioritize the interests of those most vulnerable, the Jewish groups in Germany and surrounding regions. IBM’s conscious disregard for the use of their technologies and their continual support of the Nazi Party ultimately has led the Ethics of Care framework to label them morally culpable to the the acts which they facilitated.

## Analysis of Muslim Registry Controversy

The controversy surrounding the idea of the “Muslim Registry” was sparked from certain comments made by President Trump, particularly during his campaign and the early days of his presidency. President Trump had made comments regarding “vetting” people of the Muslim faith in order to better safeguard the nation’s security. Additionally, a claim raised by Kansas Secretary of State Kris Kobach suggested that Trump’s Administration was planning to implement such a system, possible with the use of the NSEERS system put into place in 2002. NSEERS was a screening and tracking system adopted in 2002, exactly a year after 9/11, with goal of tracking foreign nationals and non-citizens that had entered the USA. This program lasted only a little over a year, and individuals on the list were officially “de-listed” in 2011.
 
It is interesting to note that there does indeed exist a precedent for such behavior, as claimed by the Liberty Conservative article. Such a precedent dates back to the internment of Japanese Americans during World War II, which was legitimized by the Korematsu v. United States Supreme Court decision. One can see that this case is similar to the controversy existing today in the sense that a group of people is being targeted based upon a certain trait.

When considering the question over whether a private corporation should be able to implement a Muslim registry, one can look to the Ethics of Care as a guideline. Firstly, it is true that hundreds of private corporations already make a business out of collecting and then selling the personal information of individuals. With this in mind, it would certainly be possible for a particular private corporation to amass data concerning the Muslim population in America. The question now becomes the purpose for which the data would be utilized by this corporation. Certain uses for personal information are benign or indeed helpful. Websites might use personal information to help set preferences and settings. One’s location might be used to set a timezone whereas one’s gender expression might be used to ensure the website uses the preferred pronouns when addressing the user. Sometimes, even this so-called helpful analytics can become controversial. For example, the wireless network Sprint, uses customer data like location, websites visited, etc. to help target advertisements. While this may not be harmful directly, many saw this as an invasion of privacy when it was first announced and still do. On the other hand, this technology could help small businesses find potential customers and build relationships in their communities. And it could help others find services and products most relevant to them. From this perspective, it’s clear that the use of personal information is not inherently bad, it’s important to read between the lines as well. It’s hard to imagine that the intent behind a Muslim registry would stop at targeted advertisements. A more insidious example of the use of personal information by a private entity were the recent accusations of wireless carriers of selling emergency location data that is supposed to be used exclusively for emergency situations. Concerningly enough, among the accused companies is Sprint, which stands as a hard reminder that even when entities claim to be collecting personal information for the greater good, darker motives may be in play. This is critical to the ethical evaluation of something like a Muslim registry. Even if a sound argument is made for its creation, what role does the potential for evil play? Can we be certain that this registry won't be weaponized against innocent people, even if the original intent was good? And any doubt that this kind of data collection could go wrong should be quenched by the horrific narrative that played out between IBM and the Nazis. It was used to divide, to alienate, and eventually to exterminate. The idea of a Muslim registry shows dark parallels to this devastating mark on history, and we’d best ensure we do not repeat those mistakes.

Cultural alienation stands as a final argument against the Muslim registry from the Ethics of Care. To label people, divide them, pigeonhole them, is to threaten the relationships and communities that bind, or should bind, our societies. To label “us” and “them” is to divide, and so the Ethics of Care must stand in strong opposition.

If such a registry were to be implemented by the government, one must once again consider the way in which data would be used, and to what extent relationships would be affected. In essence, a government exists to serve all of the people in its nation, regardless of any background information, including race and religion. Furthermore, a government should strive to protect the privacy, security, and well-being of its people, regardless of status. This purpose of governments ties directly into one of the core tenets of the Ethics of Care – relationships. The government certainly shares a unique relationship to all people who live in the country under this government in question. Accordingly, a government should aim to better these relationships continually, and definitely not to strain them.
 
On this note, instituting a Muslim registry would almost certainly aggravate relationships with Muslim people, and quite possibly to people beyond this group. The singling out of this particular group, really regardless of the purpose for which the registry would be used, can really only harm the trust that exists in the unique relationship between a government and its people. Furthermore, as the Muslim population is a minority in this country, targeting this group is even further against the beliefs of the Ethics of Care, which calls for the care of the most vulnerable groups. A government, therefore, exists to serve all of its people equally and fairly, and in this particular case, the implementation of a Muslim registry could seriously damage the vital relationship between a government and the people. For this reason, Ethics of Care would argue to disallow a government from engaging in such a practice.

## First Interview: Epicurean Ethics

For the first of the two interviews to conduct, the subject was Andres Alonso, a junior in the Epicurean ethics framework. In this interview, I planned on asking him a brief summary of his ethical framework before continuing to the main point, attempting to determine his framework’s point of view on the implementation of a registry of every Muslim citizen.

Before conducting this interview, I considered how both my framework and his would differ on this issue. From an ethics of care perspective, we would vigorously be against the Muslim registry as it would provide little to no benefits to people’s internal relationships and would most likely just be used for poor actions.  However, epicurean ethics I would anticipate does not have a clear-cut opinion on the topic, as it can be easily used to argue for or against it. For example, If the goal of the registry was to remove pain and it could be proven to do so, then, in theory, an epicurean ethicist should be all for it. However, it is also entirely possible to make an argument that the registry can only eventually lead to someone misusing that information and hence will lead to a clear increase in pain.

My initial thoughts and assumptions about epicurean ethics were in fact correct. When asked about the question, Andres sat and thought for a while considering his options, and eventually simply said that he wasn’t sure about his group’s take on the topic. He then proceeded to use very similar arguments that I had predicted to make the case both for and against the framework.

Eventually though, he concluded that an Epicurean would be against the framework because although it would make the supporters of it more “free” with less pain due to the fact that it would in their minds increase security, the long term and extreme potential of this registry to be used to create pain would completely offset the short term benefits. Also, due to the fact that there is no evidence that a registry would actually increase national security, it isn’t worth the potential pain to create the system.
        	
Having studied that frame of ethics in two of my other ethics classes I have taken at Notre Dame, I was confident that it would be a split decision on the issue, but eventual Andres did conclude that it was not as contentious as I would have believed. However, even though it was clear that Andres was very knowledgeable about his framework, I do believe that his personal ethical biases did get slightly in the way of what a true epicurean ethicist would say. This does not mean that he was incorrect, though, it just confirms what is widely known about Epicurean ethics which is that it can easily be taken in a variety of different directions simply off of a person’s own views and biases.

## Second Interview: Stoic Ethics

We interviewed a member from the Stoic Ethics group to discuss the issue of a muslim registry. The muslim registry was is an idea that was advocated for by President Donald Trump while campaigning for the 2016 Presidential Election and has since stirred a lot of controversy in the tech field. In response, groups of engineers and computer scientists pledged to never build such a registry that would target others on the basis of race or religion as such a program would be unethical. To get another perspective on this issue, I interviewed Kendyl Petitt from the stoic ethics group. From the stoic perspective, the existence of a muslim registry inherently defies what is considered to be virtuous as it promotes systemic bias and prejudice. Kendyll stated that “practicing bias or prejudice goes against our perspective that data use should be done in a virtuous manner.” From our ethics of care perspective, we also believe that the existence of a muslim registry would be in violation of our beliefs as well. While stoic ethics points to the unvirtuous nature of the registry, we would argue that the fact that such a registry was proposed from politics that is largely male dominated and functions with little input from women and people of color, that the registry is unethical. We believe that the inherently biased system, due to its lack of input from women and minorities, would create an equally biased program like the muslim registry. The stoic perspective and the ethics of care perspective both agree that the muslim registry is unjust and should not be implemented. However, our perspectives of why the registry is unjust slightly deviate. Nevertheless, we agreed that no system should exist that targets groups of people based of race, sex, religion, or sexual orientation for malign purposes. A solution from the stoic perspective would require that the registry does not target specific groups and from the ethics of care perspective, that the political system that allowed such a concept to arise be reformed and include the voices of minorities in addition to not targeting specific groups.


# Website Post 3

## Summary

Living in an increasingly interconnected world has its benefits and drawbacks for both people and corporations. Corporations in the tech industry are especially subject to issues regarding ethical responsibility as the industries of tech and big data are uncharted, and largely unregulated waters. Calls for corporate ethical responsibility are driven by shrinking government regulations and demands for greater disclosure - both of which exhibit specificity to the corporate tech industry. 

The three main issues shrouding corporate ethical responsibility in tech include information disclosures, data privacy, and anti-competitive behavior. Information disclosures are a key point in practicing transparency. They allow shareholders, financial institutions, and the general public to be informed about corporations’ financial activities and how these activities influence the environment, an important consideration for corporate ethical responsibility, society, and the overall economy. Just as recently as early 2018, the U.S. Securities and Exchange Commission (SEC) called for tech companies to disclose more information when dealing with cybersecurity risks and vulnerabilities. Because of the rise of big data, tech companies are able to amass information of the public that allows larger numbers of people to be subject to security breaches and hacks. 

The role of big data plays directly into the next major issue of data privacy. Data privacy refers to the preservation and protection of personal information that tech corporations compile from user data from being accessible by third parties. Tech companies have faced a backlash in recent months about exploiting user data and Facebook particularly has faced the brunt of this backlash. The social media tech giant had been found to have mishandled Cambridge Analytica’s violation of their company’s privacy policies and allowed nearly 50 million users’ information to be bought by the third-party group. U.S. lawmakers have moved to curb the manipulation of user data by introducing legislation that required tech companies such as Facebook, Google, Amazon, and Apple to get user permission before sharing their data. It is not surprising that lawmakers have these tech giants in mind when creating these laws and these corporations dominate the tech industry. Which then shines a light on the third major issue in corporate ethical behavior in the tech industry which is monopolistic behavior. 

Competing actors in the tech industry have asserted that companies such as Google, Facebook, and Amazon are undermining their abilities to compete as they acquire various software companies and control greater portions of the market share. In fact, European legislators have fined Google for $5 billion due to their Android antitrust violations. The fine specified that Google had bundled its search engine and Chrome software within the Android operating system which gave the tech company larger control over the market. American lawmakers have also followed suit in addressing anti-competitive behavior by having the Federal Trade Commission investigate Google’s control over online-ads and search engines. 

Overall, corporate ethical responsibility calls for the disclosure of information, the protection of user data, and non-monopolistic behavior. Each of these stipulations works to keep the interest of consumers at the forefront, promote economic welfare, and encourage consumer choice. Because of the advent of technology has revolutionized the way data is collected and preserved, tech corporations face serious issues moving forward with regards to ethical corporate behavior. 


## Critique of a Specific Unethical Corporate Action

### Summary of Action Being Analyzed

The specific unethical corporate action being analyzed is the use of power and influence by large corporations, particularly those in the tech industry, to reduce and even eliminate competing companies. With certain companies, such as Facebook or Google, having such large presences in the tech world today, they have also gained the ability to serve as major influencers in the field. Because of this, the possibility for misuse of power and unethical behavior has become a reality with such massive corporations.
 
Some more concrete examples of this type of unethical corporate behavior includes the collection of data to research, and eventually buy out, competing companies. Facebook reportedly did this with Instagram shortly before buying it in 2012. Similarly, Amazon serves as a retailer on its own marketplace alongside other retailers. Google, with its role as the predominant search engine, has the power to show certain ads, and rank pages according to its own algorithm. With such a large reach into many aspects of people’s lives, these companies have been given the power to be anti-competitive, in the sense that they can essentially monopolize a certain field.

Another instance of this is Qualcomm, At its core, Qualcomm is a classic two pronged business, with about fifty percent of its revenue coming from the creation of chips for cell phones and other digital devices, such as its famous Snapdragon semi-conductor, and the other fifty percent coming from the licensing of its more than 150,000 either granted or applied and ongoing patents at a high cost (Patsnap.com). This sort of split for a company into two different fields is not that uncommon, but what is uncommon about Qualcomm is its business model, which it claims is not only legal, but ethical, according to their CEO Steven Mollenkopf in an interview with business insider.

Qualcomm’s business model is to sell their chips, which are necessary to most phones and a lot of which are fully patent protected, to companies at a normal price, but they take a royalty off of the sale of each phone that has a Qualcomm chip inside. While this may not be problematic by itself, where the issue comes into play is the fact that they only sell their chips to companies that pay to license a large amount of Qualcomm patents in a variety of technological field. This doesn’t allow for smaller companies in the field of sales of mobile devices to realistically compete with larger technology companies simply due to the fact that they don’t have access to Qualcomm products due to their lack of capital to pay for the right to use some of Qualcomm’s other, unrelated patents (FTC v Qualcomm Incorporated, US Court District of Northern California, 2017).
 
The practice of such unethical behavior has created issues, as these big companies gain more and more influence over the tech world. The propagation of this behaviors makes it increasingly harder to challenge large tech companies, creating a slippery slope for the future.

### Why This Is Unthethical According to the Ethics of Care

The ethics of care do not support unethical corporate actions such as anti-competitive behavior. This kind of unlawful competition strongly opposes the core values in the ethics of care. The ethics of care values attentiveness, which requires recognition of others' needs in order to respond to them. Large companies such as Google, Facebook, and Amazon all control greater portions of the market share and the importance for small tech companies to exist in the market, as they all have the potential to become big companies. Many of these large companies, without caring about the rights of their small rival companies, gather their data and eventually squash them out with their power. This kind of action is not only unlawful but also unethical according to the framework of care ethics. All corporate should have the responsibility, an essential part of the ethics of care, to maintain the competitiveness of the market and create a fair market for the customers. Instead, these big companies conduct anti-competitive actions to other companies such as violating intellectual property rights and damage the competitive environment of the development of many tech companies. 

The ethics of care also focuses on vulnerability and inequality, which many weaker companies have. Especially in the world full of rivalry between powerful tech companies, the weaker companies with their own technology patents are vulnerable. Many small companies are being bought out by larger companies, with their original goals thwarted and essence changed, as they have realized their limited opportunites to develop in the environment. The large companies, on the other hand, do not acknowledge or follow the ethics of care. They do not protect the interest of the market but only extend the interest of themselves. At the same time, Data or ideas are also often very easily transmitted or stolen by stronger companies. The framework of ethics of care suggests bigger companies to follow the antitrust laws to protect the interest of smaller companies and customers. Not only would small companies benefit from a good competitive environment, but customers also receive better products or services from the different levels of competition of different corporations. 

The ethics of care encourages diversity whereas the massive anti-competitive corporates discourage them. With the dynamic of more smaller companies, they invest, research and develop more different aspects of technology whereas large companies tend to explore the more financially beneficial fields of technology. The anti-competitive tech enviornment have allowed the larger companies to head in a more narrow direction and limited its ability to expand. Protecting and promoting others interest is a part of the ethics of care, the buying or absorption of smaller companies from companies like Goodgle or Facebook has limited the smaller companies to develop, as the market is no longer competitive. 

Responsiveness is critical to the ethics of care. The competitiveness in the relationship between tech companies naturally steers away from a mutually caring and corporate friendliness. But at the same time, there are also natually healthy competitive relationships between corporates that can develop in this enviornment. However, the unlawful antitrust violations and the stealing of intellectual properties prevent such relationship from stemming. Any kind of squashing from companies should be considered unethical as they have prevented the development of healthy competitive relationships. 

### How the Corporation Could Have Atced Ethically

The Ethics of Care revolves around respectful and nurturing relationships between parties. According to this framework, therefore, the companies in question who would have participated in the unethical behavior of squashing out competition could otherwise act ethically by fostering mutually beneficial relationships with competing companies. Instead of attempting to eliminate or acquire competitors, large corporations could seek to establish business partnerships that would increase the well-being of both parties. For example, a large corporation like Amazon could create regional and local partnerships to aid with the distribution and storage of products. Similarly, Google would certainly put on a good image by treating all pages equally in a page rank system. This in turn would create trust and respect from smaller, competing companies.
 
Ethics of Care is also very much concerned about caring for the vulnerable. As large entities with a considerable amount of power and influence, big tech corporations have an ethical duty to look out for companies that may be struggling, or that simply do not have the reach that larger corporations do. As discussed before, big corporations could seek to create partnerships or “mentoring” relationships to other corporations, as this would certainly promote good relationships. On top of this, healthy competition would not only benefit the companies involved, but also the corresponding field as a whole, since competition would promote innovation and changes for the better.
 
The ethical framework laid out by the Ethics of Care is supremely relevant to the unethical corporate behavior analyzed here. If companies would seek to build up strong relationships rather than tear them down, the corporate world could become stronger, more competitive, and ultimately more forward-looking.

## Comparison of Methods For Solving Unethical Behavior

### Summary of Proposed Methods

Different instances of unethical corporate behavior require specific responses to correct the behavior. Some of the more pressing areas of unethical corporate behavior are monopolistic actions and the exploitation of user data. Anti-competitive behaviors exhibited by firms are restricted by regulatory legislation. Regulations could take the form of company break-ups or the prevention of new acquisitions.
 
Company break-ups would require tech giants to relinquish their control auxiliary tech platforms in order to open up the market share and prevent monopolies. For example, in the United States, the Department of Justice could mandate that YouTube is separated from Google or that Facebook is split from Instagram. The prospect of breaking-up companies is not new as antitrust laws have been a force for anti-monopoly legislation for centuries. In Europe as well, the European Commission has taken action to tackle the monopolistic tendencies of leading tech corporations. The commission recently fined Google for $5 billion over bundling its search engine within Android products.
 
The strategy of breaking-up tech corporations does not necessarily have to be left in the hands of government agencies. Corporations could act preemptively when faced with early charges of anti-competitive behavior by handling their own company break-up and deciding which area to relinquish ownership of rather than allowing federal agencies to decide. The policy of breaking-up companies or “trustbusting” is a particularly favorable endeavor on the left. Because it is regulatory in nature, it allows the government to have greater oversight of big tech companies such as Facebook, Google, Amazon, and Apple which as these companies amass large quantities of user data.
 
A method to combat the exploitation of user data is the call for data portability and interoperability. Data portability refers to the idea that users of tech companies’ software should be essentially able to pack up their personal user data and store that information elsewhere, whether that be in a competitor’s software or the user’s personal drive. The purpose of this method is to give users greater control over their own data and the freedom to decide how that data is stored. Furthermore, interoperability refers to the sharing of user data with competitors. This would weaken tech giants’ hold on personal user data that allows them to control large shares of the tech market.
 
Similar to the method of breaking-up tech corporations, the strategy of requiring data portability and interoperability relies on legislative regulations. In Europe, for example, the General Data Protection Regulation is seeking to require that the service of data portability be available on other platforms that collect user data. Both of these methods to combat unethical corporate behavior rely on government oversight which is easily subjected political sentiments that advocate for or against government intervention. It is no surprise though that both methods to combat unethical corporate behavior in tech relies on legislative action as the tech world is largely uncharted waters and can change rapidly. Therefore, it is difficult for legislation to keep up with new features and developments in the tech industry which is why there are constant calls for greater legislative action to curb new developments. 

Additionally, both methods of combating unethical corporate behavior have their drawbacks. With regard to breaking-up tech companies to prevent monopolistic behavior, these tech companies could avoid such action by lobbying legislators who vote on antitrust laws in big tech. For example, in 2017, about $50 billion was spent by tech industry companies to lobby against regulatory laws that would curb acquisitions that contribute to the creation of near monopolies. And with regard to data portability, such services exist as aforementioned, however users are not likely to put in the effort to take advantage of such services. Therefore, companies like Google, Amazon, and Facebook are still left with control over large amounts of user data. Furthermore, as with breaking-up companies and data portability, interoperability also has its drawbacks. Since it calls for tech companies to share their user data with other up and coming companies to ensure their ability to compete, this process is not necessarily in the best interest of the user as their data is being distributed without user consent.

It is important to note that neither the method of breaking-up tech giants or requiring data portability or interoperability can completely deter unethical corporate behavior. There are many avenues through which corporations can circumvent legislations curbing their large control over the market share and user data whether through lobbying or relying on user ignorance of the issues. These two means of ensuring ethical corporate behavior are however a good place to start and should be coupled with greater education of users and how their data is being used by corporations. 

### Comparison

The two proposed methods are, in many ways, closely tied in the realm of correcting unethical corporate behavior. When comparing the two directly, it is easiest to view the first method as a preventative measure before the second becomes more of a problem. By not allowing companies to become monopolies, users’ data is inherently safer by effectively limiting the ways companies can misuse it. Additionally, the rise of these massive tech companies has led to an age where data is king; by regulating the size of companies, not only does the chance of data misuse decrease, but the amount of private data collected also decreases. Moreover, the first proposed method serves as a general positive by allowing new companies, ideas, and technologies to flourish fairly under the United States’ capitalist principles. The second method is more specifically concerned with tech companies and limiting the potential harm that they can cause with data.

It is interesting to observe that the first proposed method would benefit those on the business side and the second method would benefit those on the consumer side. Both issues discussed could theoretically be fixed through the companies acting properly and safely, but realistically need to be addressed by implementing suggested fixes through legislation. Even if the companies were acting in the public's’ best interest, users would probably be safer in the end with an extra measure of government regulation. Despite companies lobbying directly against these proposed methods, both proposals are not meant to disrupt the growth of any companies; legislation would be put in place only to ensure competitive fairness and, above all, increase consumer safety. 

### Conclusion

According to the  Care Ethics Ethical Framework,  the proposal that is most favorable in addressing the issue of monopolies in companies would be to make tech giants require portability and interoperability of user data as opposed to breaking up and separating the companies in question (like Youtube and Google). Our framework would say that giving the users/customers power over the data that these companies have over them would build a greater sense of trust and openness with these companies. If the users believed that these companies were using their data for nefarious reasons, they could see exactly what they are tracking and make the decision if they want to maintain the relationship with the company or sever it. This power given to the user would entice these companies to promote healthy relationships with their customers through their practices. Finally, this proposal would make it so that you must share data with competitors, this opens up to possibility of collaboration and partnerships with previous competitors which has a potential to build relationships with them. Overall this proposal is seen as more favorable than breaking up companies as it emphasizes the power of the customer and builds a sense of trust, strengthening the company-customer relationship.
 
## Proposal to Enforce Corporate Social Responsibility

The Ethics of Care framework is centered around relationships that involve a vulnerable party. So, to reinforce Corporate Social Responsibility, we propose an approach that examines the position of power the corporation holds and what parties are affected by them. After determining this, we will hold companies accountable by evaluating the impact they have on these relationships and whether it is positive or negative. To hold companies accountable, we will call on governments to impose penalties for corporations that abuse these relationships and policies that continuously monitor companies to make sure they currently are not abusing relationships. Along with this, we will try to publish as much information about the social impact companies have on different parties.

Companies have a lot of power in the world, and more so in the United States. In many cases, masses of people rely on and are at the mercy of these companies. For instance, many people rely on different medications and equipment that pharmaceutical and biotech companies produce. If they were not able to get these products for whatever reason, their livelihood could be greatly impacted. Along with customers that rely on their products, companies have a lot of power to influence governmental policy. Many industries form special interest groups that try to push forward their agenda. In this way, companies can shape how the country and the world operates, impacting millions, if not billions of people.

We would consider corporations to abuse these relationships if they use their power to benefit themselves by hurting the people in these relationships. Going back to the pharmaceutical example, there have been cases in the past where corporations have drastically increased the price of medications, not because producing the medications cost increased, but to increase their profit. We would consider this irresponsible. We would call on policy to punish a company like this. Along with that, we would create a social media campaign exposing what the company did and highlight some of the individuals it hurt. In fact, this response has happened several times. In terms of special interest groups, if a company were to lobby for a policy that would hurt vulnerable people solely out of their business interests, we would consider this irresponsible. We would call for policy that limits how much a special interest group can influence legislation that is passed. Along with this, we would try to publish as much information about what companies support lobbying for what legislation, tying corporations to specific policies.

Overall, our approach aims to highlight the effects corporations’ actions to increase profits have on the relationships they have with vulnerable parties. Often times, the phrase “that’s just business” is meant to devalue these relationships. However, our proposal would try to change this culture to actually emphasize these relationships. 

To show how our proposed solution would correct unethical behavior, we will look at the Equifax hack. The Equifax hack refers to the 2017 data breach that leaked hundreds of millions of Americans personal information, including names, social security numbers and addresses. Negligence and carelessness were two of the reported reasons for the breach.

Equifax’s has a major position of power, even compared to other huge corporations. As a Credit Reporting Agency, they have data and information about millions of people, some of whom did not even sign up for Equifax. So, they basically have relationships with every person in the country. The information is extremely sensitive as well. Losing a Social Security number could lead to a stolen identity, major headaches and loss of life savings. Equifax’s carelessness and negligence can be attributed to corporate irresponsibility, which may have resulted from incompetent executives or to raise the bottom line. Regardless, the lack of resources geared towards security had a reason that benefited the company, at the expense of the other parties involved. Our proposal would push for governmental policies that would significantly penalize a company that does this, preventing companies in the future from doing it again. We would also support policies that create watchdogs to make sure that companies are adhering to the standard. We would also call Equifax to have a public hearing about what they have done to fix the issues that resulted in the breach.

## Resources

[https://www.cnet.com/news/equifaxs-hack-one-year-later-a-look-back-at-how-it-happened-and-whats-changed/](https://www.cnet.com/news/equifaxs-hack-one-year-later-a-look-back-at-how-it-happened-and-whats-changed/)

[https://www.theverge.com/2018/9/5/17805162/monopoly-antitrust-regulation-google-amazon-uber-facebook](https://www.theverge.com/2018/9/5/17805162/monopoly-antitrust-regulation-google-amazon-uber-facebook)

[https://techcrunch.com/2018/02/21/the-sec-says-companies-must-disclose-more-information-about-cybersecurity-risks/](https://techcrunch.com/2018/02/21/the-sec-says-companies-must-disclose-more-information-about-cybersecurity-risks/)

[https://swirled.com/facebook-user-data-breach/](https://swirled.com/facebook-user-data-breach/)

[https://www.economist.com/briefing/2018/01/20/the-techlash-against-amazon-facebook-and-google-and-what-they-can-do](https://www.economist.com/briefing/2018/01/20/the-techlash-against-amazon-facebook-and-google-and-what-they-can-do)

# Website Post 2

## H-1B Visas

One of the biggest arguments of the H-1B visa system is that it allows workers from other countries to work in the United States for American companies. According to the USCIS H-1B general requirements, these foreign employees must be highly skilled workers who have a Bachelor's degree or equivalent education or training. This essentially means that the program allows for high-skilled workers to come into the US and fill roles that are highly in demand, essentially combatting local talent shortages especially in the tech industry that is booming.  While under the H-1B visa the worker can apply for permanent residency in the US, which creates a path for foreign nationals to become US citizens if they so wish.  Another argument in favor of the H-1B visa system is that these holders typically become small business owners and job creators, who drive innovation and help build the US economy. Finally, the last arguments for the H-1B visa system is that it allows companies to hire workers with a wider range of upbringings, experiences, and perspectives essentially creating diversity in their company.  

The biggest argument against the H-1B visa is that these workers are getting taken advantage of by the companies that hire them. IEEE-USA points out in the article titled “Commentary: The H-1B Visa Problem as IEEE-USA Sees It” that  Smartorg pays software engineers on H-1B visas in Menlo Park only $80,000 annually, which is a ridiculously low salary for the San Jose region, compared to Facebook's $138,294. As a consequence, companies can hire the same level of talent for a cheaper rate, which some argue takes jobs away from American Workers. People see the H-1B as a tool used by companies to avoid hiring American workers and avoid paying American wages. In addition to this, employees cannot obtain an H-1B visa unless they are sponsored by an employer. The employer must typically cover any legal fees required to process their sponsorship if they even acquire an H-1B visa as there is a limited number of them available. In addition to this, in the article, “Engineers Are Leaving Trump’s America for the Canadian Dream” having a H-1B visa comes with a lot of uncertainty as an employer can fire their employee and take away their right to be in the country, creating significant stress. As a result, many of these workers apply for green cards, but as the article states, many have been waiting “a decade or more for their green cards and still don't have them”.

Applying Care Ethics to the H-1B visas situation is somewhat complicated. On one hand, the emphasis on relationships could lead one to believe that this ethical framework would employ a “more is better” policy, and simply take as many visas as citizens of other countries require. Despite being unfeasible from a logistics standpoint, followers of Care Ethics would be hesitant to take visas due to the several aforementioned current flaws with the system; a valid question being “Is it really better to take in everyone if they might be exploited, treated unfairly, and generally not cared for as well as US citizens?”. Ultimately, our ethical of framework would have a lot to change on both sides -- that is, how many H-1B visas are allowed and the employer-employee dynamic with visa workers -- of the controversy as it is currently.

First, Ethics of Care would suggest that visas should be easier to obtain. This way, those looking to come to the United States could fulfill their dream, jobs would get filled within companies, but, most importantly, relationships could flourish and continue to give people new perspectives into the lives of others around the world. This way, when both the people receiving visas and their employers/coworkers move forward in life, they can take their new, more worldly points of view into future relationships and actions. In order for both parties to benefit, both sides of process must change. This means it should be quicker for a person to receive a green card, or they should be provided more benefits during their visa duration. Additionally, employers should get an easier time trying to bring on/sponsor a citizen of another country. 

Second, Care Ethics would not tolerate the current exploitation of visa workers. Companies getting employees with visas can be good, but getting those employees just to avoid paying a standard industry wage is not okay. Furthermore, workers with visas need to receive more benefits, rights, and/or guarantees concerning their status as employees in the US. If a company has all the power over their visa worker(s), it can take advantage and abuse in its relationships. Ethics of Care would suggest that all employees do the same work be paid the same, since that seems like the most practical and fair way to maintain and grow relationships.

With these fundamental changes to the state of visas in the US, followers of Ethics of Care would be big proponents of the H-1B visa system. 

## Google Internal Memeo

The internal Google memo that was circulating inside the company in 2017 received much backlash both from inside the company and out. The employee who wrote it was eventually fired and his ideas dismissed. The memo actually addressed several different issues that the author wanted to bring up. The author discussed the idea that left and   ideals have a difference of opinion on when it comes to disparities like a gender gap. The author says that left ideals hold that gaps like this are because of injustices while right ideals would say that these gaps are natural. The author goes on to say that instead of bias against women in tech, their biology simply makes working in tech not an appealing place for women. Finally, the author lists some things Google might do in order to close the gender gap that are not, in the author’s opinion, discriminatory as some of their other initiatives are such as classes only for a certain race/gender. The author makes his viewpoint very clear by constantly referring to many of the diversity and inclusion practices that Google employes as discriminatory. As to who is being discriminated by these practices the authors never explicitly states but it can be implied that it is white men.

In terms of the ethics of care, most of the arguments presented by the author would absolutely be morally bad, there are a few points in the memo through that the ethics of care might agree with. The first of these points is the idea that is presented in the memo that in order to close the gender gap we could institute programs such that make tech industries more appealing to women. The Ethics of Care came about trying to come up with a system of ethics that appeals more to women, by instituting programs that both are good for the business but also help women relate to the company by being more compassionate, more people oriented, and more focused on how women work and what a woman wants out of a job. Going off of this the Ethics of Care might also acknowledge that men and women do indeed have some difference in traits as a whole and when trying to close the gender gap these traits should be taken into account. 

In contrast, the Ethics of Care would have a lot of issues with many of the the viewpoints put forward in the memo. One of the main issues the Ethics of Care would have is that the author says in order to make unbiased decisions one should leave feelings out of the decision. The Ethics of Care would consider this to be terrible as caring for others is a central part of the Ethical System.  In order for one to evaluate how ethical something is one must consider how one is caring for others and caring for oneself. In this same line of thinking, the author saying that programs that help traditionally underrepresented people are discriminatory would not be in line with the Ethics of care as they are not caring about those underrepresented people and this line of thought doesn’t take into account why these programs exist. A person following the Ethics of Care would see that these programs are needed because for some reason or another these people are underrepresented and need care. Finally one of the final points that the Author raises that the Ethics of Care would take issue with is the idea that gender issues should be demoralized, gender issues deal with people and relationships so by definition the Ethics of Care would say that gender issues absolutely fall under morality and should be thought of as such.  In closing the Google Memo is clearly a very polarizing topic and it helps to examine it in the ways that we have here to fully understand its context and its goals. 

## Analysis of Gender Bias in Tech

There are several issues concerning gender affecting the technology industry today. First, as it stands, the male to female ratio in technology jobs, which some studies say is 80/20, does not reflect the population ratio, which is roughly 50/50. This is a very complex issue and there are a few ideas as to why it exists. The leading theory is that, from a young age, across a population, boys and girls are implicitly pushed towards certain career paths. Generations and generations of gender roles have created these perceptions. Seeing mostly men in technological roles creates a perception that tech. jobs are more suited for men than women. Others take the point of view that, due to evolution, men are physically more suited for jobs in technology than women and that is why this gender gap exists. This is the nature versus nurture debate. A few years ago, an internal Google memo supporting this viewpoint challenged diversity and minority programs at technology companies and created a lot of controversy throughout the technology industry. 

Another Gender issue is sexual harassment. In a recent article, CNN outlined the stories of several women who have been harassed in the tech industry. In some instances, Venture Capitalists and investors used their positions of power to sexually harass female entrepreneurs. Because they had the power to withdraw funding from the entrepreneur's company, they were able to get away with extremely inappropriate behavior. This is a result of both the major gender gap in the industry and extreme amounts of money creating major power imbalances.

To respond to the first issue about the gender gap, the Ethics of Care framework would support the theory that it is due to historical gender roles. Feminist Ethics and the Ethics of Care were created in response to the perceived gender bias in traditional ethical frameworks. Furthermore, Ethics of Care would call on women in technology roles to develop relationships with young girls and women and help show them that they are able to be successful in the field if they want to. This does not necessarily just need to be between an adult and a child. For instance, an executive helping a recent graduate would be important as well. These relationships are what the Ethics of Care is based on. Eventually, these relationships would bring more women into technology, reducing the common perception that tech. jobs are more suited for men and close the gender gap.

In response to the problem with sexual misconduct, Ethics of Care would suggest that it is the responsibility of everyone in the environment to actively and vocally not tolerate that type of behavior. In order to preserve relationships with female coworkers and all other females, people would need to stand up for them or else damage their relationships. Tolerating sexual assault in a single instance contributes to a culture of tolerance, which will impact all the females around someone. Lastly, it is important to note that these issues will not be solved overnight. Changing a culture takes a lot of time and will require patience and persistence. However, forming strong relationships and taking on these issues as a group will help strengthen these traits and push progress forward.

## Analysis of Race and Ethnicity Issues in Tech

In the technology field, particularly in the scope of computer science, there without a doubt exists a bias towards race and ethnicity. In terms of race and ethnicity, majorly underrepresented groups, both on the academic level and in the professional field, include people of African, Hispanic, or Native American heritage, as well as international people. Among other issues, people who identify with these ethnicities and backgrounds have been reported to feel isolated or unrepresented in the technology field as a whole, which in turn has created a severe lack a diversity and variance of perspectives.
 
One of the biggest areas where this problem persists is in education. According to research studies, black students are less likely to have the opportunity to take computer science classes in school, and furthermore, black and Hispanic students are less likely than white students to have access to computers at home. These small examples, combined with a plethora of related research one can find online, point to a culture in which students of certain races and ethnicities have not received the opportunities that would help to inspire future computer science studies. This issue is only exacerbated when looking at the diversity of computer science majors, where the groups discussed here only make up a fraction of students pursuing a computer science degree at the university level.
 
A related issue that highlights a lack of ethnic diversity in the tech field can be observed from the professional field, in which minorities are likewise underrepresented. While this can be seen as the result of the issues existing in the education process, as discussed above, these deficiencies are nevertheless prominent. The way in which tech companies recruit students is something that has seriously affected the makeup of the workforce in the tech industry.  Similarly, the dominance of people who identify as white, including in the workforce but especially in upper-level management, has certainly also contributed to the problem.
 
Although the Ethics of Care framework does not have a clear-cut solution to lessening and ultimately eliminating biases towards race and ethnicity in the tech field, one can nevertheless apply its principles to this complex issue. In terms of education, when one considers a loving and caring relationship, it is beyond doubt that the parties involved in this relationship both would wish the best for each other. As a result, Ethics of Care would promote the encouragement of pursuing whatever interests best suit and benefit a given person. If someone truly cares for another, then this person would help a fellow friend achieve the highest success possible, regardless of race or ethnicity. If someone we care about expresses an affinity for the tech field, we must foster this passion, so as to strengthen our caring relationship with this person.
 
Similarly, the professional field can be strengthened by an uptake in ethnic diversity, which would certainly promote unique and diverse relationships. Part of caring for others entails including all people, and in terms of the professional field, this would manifest itself in the recruitment of all people, with the goal of creating a workforce comprising of diverse-minded, intelligent, and hard-working people. Ultimately, the inclusion of all people is tantamount to caring for others, so Ethics of Care is undoubtedly pertinent to the issues regarding race and ethnicity in today’s tech world.

## Resources

[https://www.uscis.gov/working-united-states/temporary-workers/h-1b-specialty-occupations-dod-cooperative-research-and-development-project-workers-and-fashion-models](https://www.uscis.gov/working-united-states/temporary-workers/h-1b-specialty-occupations-dod-cooperative-research-and-development-project-workers-and-fashion-models)

[https://spectrum.ieee.org/view-from-the-valley/at-work/tech-careers/commentary-the-h1b-problem-as-ieeeusa-sees-it](https://spectrum.ieee.org/view-from-the-valley/at-work/tech-careers/commentary-the-h1b-problem-as-ieeeusa-sees-it)

[https://www.bloomberg.com/news/features/2018-04-20/h-1b-workers-are-leaving-trump-s-america-for-the-canadian-dream](https://www.bloomberg.com/news/features/2018-04-20/h-1b-workers-are-leaving-trump-s-america-for-the-canadian-dream)

[https://money.cnn.com/technology/sexual-harassment-tech/](https://money.cnn.com/technology/sexual-harassment-tech/)

[https://smallbiztrends.com/2018/03/women-in-technology-statistics.html](https://smallbiztrends.com/2018/03/women-in-technology-statistics.html)

[https://www.stanforddaily.com/2015/01/16/addressing-ethnic-diversity-in-computer-science/](https://www.stanforddaily.com/2015/01/16/addressing-ethnic-diversity-in-computer-science/)

[https://www.bloomberg.com/features/2016-howard-university-coders/](https://www.bloomberg.com/features/2016-howard-university-coders/)

[https://www.usatoday.com/story/tech/news/2016/10/18/google-gallup-computer-science-girls-blacks-hispanics/92335498/](https://www.usatoday.com/story/tech/news/2016/10/18/google-gallup-computer-science-girls-blacks-hispanics/92335498/)




# Website Post 1

## Statement Of Purpose

### What Makes An Action Ethical According to the Ethics of Care?

To evaluate actions with the Ethics of Care framework, one must look at how the action affects the person performing the action and the people that are being cared for by that person. If an action ignores the well-being of either of those two parties, it is unethical. However, if both parties’ interests are met, the action is ethical. Furthermore, the relationships that are impacted by the action should be evaluated. In the framework, relationships are between unequal parties. For example, a parent and a child. Because one’s moral development is defined by the relationships that they are involved in, actions that sever relationships are unethical and actions that strengthen relationships are ethical. In summation, the Ethics of Care framework emphasizes maintaining and strengthening connections to others, as well as protecting the interests of those involved, as a collective unit.

### What triggers the need to evaluate how ethical an action is?

With the framework of Care Ethics in mind, actions must be evaluated for how ethical they are when these actions impact those we care about or are connected to. The Ethics of Care emphasizes the connections to others and maintaining those connections, as well as protecting the interests of those involved, as a collective unit. When making decisions that affect others, we must be mindful of how ethical our decision will be. In this way when some action impacts a relationship between any two parties the ethics of care would ask one to step in and evalute how ethical the action is. This can be many different kinds of relationships including by not limited to: company and customer, employer and developer, and developer and customer.  


### What predisposition do people have to act ethically according to the Ethics of Care?

According to the ethics of care, the predisposition people have to act ethically is influenced by gender. Men are predisposed to act in an ethical manner according to abstract ideas of justice and duty, whereas women act ethically according to ideas of empathy and compassion. Because ethics and what one deems to be ethical is rooted in a moral system, men and women are predisposed to acting ethically with regard to their respective moral systems.  This idea is essential to the ethics of care as its founder, Carol Gilligan, sought to make clear that men and women have distinct understandings of morality which influence the way in which they respond to ethics and behaving ethically.

### Issues in technology that the Ethics of Care would say much about

The ethics of care have a lot to say about in many different issues in computer technology. 

1.	Software and Users 
	Many computer technology companies, especially social network platforms do not preserve and protect the rights and information of the users. According to the ethics of care, this information should be held responsible by the software companies and realize the vulnerability of the users. Users should be treated with care and respect and therefore companies should follow through with their responsibilities and actively prevent users’ information to be stolen.

2.	User Experience
	The user experience that is provided to different users must be speculated and paid special attention to. It has been an issue that many female users have reported their gender identity were being insulted in their experience interacting with certain software, or information provided by users. These software companies are accountable for their messages and should respect different genders, races, and disabilities. Many companies have refined their actions, such as providing emojis of different gender and races, designing their interface catering to users with color vision deficiencies.

3.	In the Workplace
	At workspaces, especially in computer technology working environment, there is a gender imbalance between male and female engineers and often times female engineers are being disrespected. The ethics of care emphasizes protecting the interests and rights of all genders and races and employers should address such issues and provide female engineers with equal opportunities and respect. Administrators of different workspaces should also acknowledge details of minority workers and providing them with a good working environment and the care they needed.

## Ethics of Care and IEEE Code of Conduct

When comparing the IEEE code of ethics with the ethical framework laid out by Ethics of Care, one can observe that the IEEE does partly focus on the relationship of professionals to the public and to fellow colleagues. This notion of relationship to others is something on which Ethics of Care places great emphasis. This similarity can especially be seen in points one and eight of the IEEE code of ethics, which concern the general welfare of the public and the treatment of other persons, respectively. Likewise, points nine and ten stress the importance of proper and professional behavior in relation to the public and colleagues. 


On the other hand, there does indeed exist certain differences between the two, mainly in the overall goal of the respective schools of thought. In the IEEE code of ethics, a distinctly professional diction is used, and one can see this focus in lines such as “to maintain and improve our technical competence and to undertake technological tasks”. In addition to this, IEEE outlines broad guidelines for proper behavior in the technical field, as well as how to deal with emerging technologies. Ethics of Care, however, is far more concerned with personal relationships, rather than providing a guideline to ethical behavior in a professional sense. On this note, a major difference between the IEEE code of ethics and Ethics of Care lies in the fact the IEEE provided a very general framework in its code, while Ethics of Care emphasizes a much narrower scope, attempting to focus on the very important aspect of human interaction.


The most notable missing part from the IEEE code of ethics with regards to incorporating the Ethics of Care is a sense of care and benevolence between professionals in the technical field and clients, or those who are recipients of the goods, services, etc. This sense of a caring relationship between people can certainly also be applied between peers in the field. If the IEEE code of ethics were to add a few points to guide the nature of ethical relationships within the field, then it would undoubtedly be more in line with the Ethics of Care.

## Ethics of Care and ACM Code of Conduct

The ACM code of ethics is almost entirely geared towards applying ethics towards a variety of professions, such as providing guidelines for those in a higher up occupation so as to not abuse their power against their employees. An ethicist following the ethics of care would be in opposition to the pure purpose of this code of ethics, primarily due to the fact that it is still encouraging for those in power to view their employees as subordinates and simply do not abuse them, while an ethicist of care would argue that employees should be seen as equals and that the primary focus should be building a relationship with them. Hence, this is a key difference between the two systems. Another difference is the fact that the ACM code of ethics emphasizes that the “central concerns” of computing work are “the public good” and “high quality”, while ethics of care based system would argue that relationships between both customer and company as well as inter-employee relations should be the key focus. However, both of these ethical guidelines do have similarities, particularly in the fact that the ACM still does stress that professionals still need to care for their employees and treat them with respect. Also, the ACM states that all its professionals should” Articulate, encourage acceptance of, and evaluate fulfillment of social responsibilities by members of the organization or group”, which in turn also encourages for people to build relationships inside of their own organization to hopefully improve the quality of the group. The ACM code of ethics, though, still could learn from the ideologies of Ethics of Care, maybe by adding a few more points stressing the fact that both professional and friendly relationships between professionals should be encouraged as it helps people to grow and have a more enjoyable life.

## Ethics of Care and ICCP Code of Conduct

There are a number of notable similarities between Ethics of Care and the ICCP Code of Ethics. As Ethics of Care stresses the importance of relationships, one could look to the ICCP’s Code of Ethics’ Code of Conduct section. Specifically, the subsections on Integrity (2.5), Accountability (2.7), and Protection of Privacy (2.8) all particularly align with some principles of Ethics of Care. Integrity in a hypothetical relationship of ICCP members works both ways -- employers should not take advantage of their employees, and employees should be upfront with their employers. Accountability requires competence and responsibility, both integral in Ethics of Care. Last, for Protection of Privacy, the trust of both parties is essential for relationships, so there is quite a bit of overlap between the code and Care Ethics. 


Despite the many similarities, there are differences between the Ethics of Care framework and the ICCP Code of Ethics. For example, there are large parts of the ICCP’s Code of Ethics concerning how a member may lose their status, which seems to directly conflict with the fundamentals of Care Ethics (by limiting relationships). Additionally, a lot of the guidelines seem to exist as reminders of professional and societal obligations. In fact, the word “obligation” appears 3 times in the first 4 sentences of the ICCP Code of Ethics. Ethics of Care, on the other hand, stress the difference between obligation and responsibility, claiming that obligations are limited to socially constructed roles while responsibilities aren’t. 


This difference between words could actually be expanded to address how the ICCP Code of Ethics could improve by taking from Care Ethics. Where Ethics of Care is about the personal, the ICCP Code of Ethics is about the professional. If the ICCP were to expand their Code to include more on the interpersonal connections in the work environment, they could address this missing area. 



